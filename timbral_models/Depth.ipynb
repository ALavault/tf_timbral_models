{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "from scipy.signal import spectrogram\n",
    "import timbral_util\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import warnings\n",
    "\n",
    "def timbral_depth(fname, fs=0, dev_output=False, phase_correction=False, clip_output=False, threshold_db=-60,\n",
    "                  low_frequency_limit=20, centroid_crossover_frequency=2000, ratio_crossover_frequency=500,\n",
    "                  db_decay_threshold=-40):\n",
    "    \"\"\"\n",
    "     This function calculates the apparent Depth of an audio file.\n",
    "     This version of timbral_depth contains self loudness normalising methods and can accept arrays as an input\n",
    "     instead of a string filename.\n",
    "\n",
    "     Version 0.4\n",
    "\n",
    "     Required parameter\n",
    "      :param fname:                        string or numpy array\n",
    "                                           string, audio filename to be analysed, including full file path and extension.\n",
    "                                           numpy array, array of audio samples, requires fs to be set to the sample rate.\n",
    "\n",
    "     Optional parameters\n",
    "      :param fs:                           int/float, when fname is a numpy array, this is a required to be the sample rate.\n",
    "                                           Defaults to 0.\n",
    "      :param phase_correction:             bool, perform phase checking before summing to mono.  Defaults to False.\n",
    "      :param dev_output:                   bool, when False return the depth, when True return all extracted\n",
    "                                           features.  Default to False.\n",
    "      :param threshold_db:                 float/int (negative), threshold, in dB, for calculating centroids.\n",
    "                                           Should be negative.  Defaults to -60.\n",
    "      :param low_frequency_limit:          float/int, low frequency limit at which to highpass filter the audio, in Hz.\n",
    "                                           Defaults to 20.\n",
    "      :param centroid_crossover_frequency: float/int, crossover frequency for calculating the spectral centroid, in Hz.\n",
    "                                           Defaults to 2000\n",
    "      :param ratio_crossover_frequency:    float/int, crossover frequency for calculating the ratio, in Hz.\n",
    "                                           Defaults to 500.\n",
    "\n",
    "      :param db_decay_threshold:           float/int (negative), threshold, in dB, for estimating duration.  Should be\n",
    "                                           negative.  Defaults to -40.\n",
    "\n",
    "      :return:                             float, aparent depth of audio file, float.\n",
    "\n",
    "     Copyright 2018 Andy Pearce, Institute of Sound Recording, University of Surrey, UK.\n",
    "\n",
    "     Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "     you may not use this file except in compliance with the License.\n",
    "     You may obtain a copy of the License at\n",
    "\n",
    "       http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "     Unless required by applicable law or agreed to in writing, software\n",
    "     distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "     See the License for the specific language governing permissions and\n",
    "     limitations under the License.\n",
    "    \"\"\"\n",
    "    '''\n",
    "      Read input\n",
    "    '''\n",
    "    audio_samples, fs = timbral_util.file_read(\n",
    "        fname, fs, phase_correction=phase_correction)\n",
    "    audio_samples = audio_samples[:128*128]\n",
    "    fs = float(fs)\n",
    "    '''\n",
    "      Filter audio\n",
    "    '''\n",
    "    # highpass audio - run 3 times to get -18dB per octave - unstable filters produced when using a 6th order\n",
    "    audio_samples = timbral_util.filter_audio_highpass(\n",
    "        audio_samples, crossover=low_frequency_limit, fs=fs)\n",
    "    audio_samples = timbral_util.filter_audio_highpass(\n",
    "        audio_samples, crossover=low_frequency_limit, fs=fs)\n",
    "    audio_samples = timbral_util.filter_audio_highpass(\n",
    "        audio_samples, crossover=low_frequency_limit, fs=fs)\n",
    "\n",
    "    # running 3 times to get -18dB per octave rolloff, greater than second order filters are unstable in python\n",
    "    lowpass_centroid_audio_samples = timbral_util.filter_audio_lowpass(\n",
    "        audio_samples, crossover=centroid_crossover_frequency, fs=fs)\n",
    "    lowpass_centroid_audio_samples = timbral_util.filter_audio_lowpass(\n",
    "        lowpass_centroid_audio_samples, crossover=centroid_crossover_frequency, fs=fs)\n",
    "    lowpass_centroid_audio_samples = timbral_util.filter_audio_lowpass(\n",
    "        lowpass_centroid_audio_samples, crossover=centroid_crossover_frequency, fs=fs)\n",
    "\n",
    "    lowpass_ratio_audio_samples = timbral_util.filter_audio_lowpass(\n",
    "        audio_samples, crossover=ratio_crossover_frequency, fs=fs)\n",
    "    lowpass_ratio_audio_samples = timbral_util.filter_audio_lowpass(\n",
    "        lowpass_ratio_audio_samples, crossover=ratio_crossover_frequency, fs=fs)\n",
    "    lowpass_ratio_audio_samples = timbral_util.filter_audio_lowpass(\n",
    "        lowpass_ratio_audio_samples, crossover=ratio_crossover_frequency, fs=fs)\n",
    "\n",
    "    '''\n",
    "      Get spectrograms and normalise\n",
    "    '''\n",
    "    # normalise audio\n",
    "    lowpass_ratio_audio_samples *= (1.0 / max(abs(audio_samples)))\n",
    "    lowpass_centroid_audio_samples *= (1.0 / max(abs(audio_samples)))\n",
    "    audio_samples *= (1.0 / max(abs(audio_samples)))\n",
    "    # set FFT parameters\n",
    "    nfft = 4096\n",
    "    hop_size = int(3 * nfft / 4)\n",
    "    # get spectrogram\n",
    "    if len(audio_samples) > nfft:\n",
    "        freq, time, spec = spectrogram(audio_samples, fs, 'hamming', nfft, hop_size,\n",
    "                                       nfft, False, True, 'spectrum')\n",
    "        lp_centroid_freq, lp_centroid_time, lp_centroid_spec = spectrogram(lowpass_centroid_audio_samples, fs,\n",
    "                                                                           'hamming', nfft, hop_size, nfft,\n",
    "                                                                           False, True, 'spectrum')\n",
    "        lp_ratio_freq, lp_ratio_time, lp_ratio_spec = spectrogram(lowpass_ratio_audio_samples, fs, 'hamming', nfft,\n",
    "                                                                  hop_size, nfft, False, True, 'spectrum')\n",
    "\n",
    "    else:\n",
    "        # file is shorter than 4096, just take the fft\n",
    "        freq, time, spec = spectrogram(audio_samples, fs, 'hamming', len(audio_samples), len(audio_samples)-1,\n",
    "                                       nfft, False, True, 'spectrum')\n",
    "        lp_centroid_freq, lp_centroid_time, lp_centroid_spec = spectrogram(lowpass_centroid_audio_samples, fs,\n",
    "                                                                           'hamming',\n",
    "                                                                           len(\n",
    "                                                                               lowpass_centroid_audio_samples),\n",
    "                                                                           len(\n",
    "                                                                               lowpass_centroid_audio_samples)-1,\n",
    "                                                                           nfft, False, True, 'spectrum')\n",
    "        lp_ratio_freq, lp_ratio_time, lp_ratio_spec = spectrogram(lowpass_ratio_audio_samples, fs, 'hamming',\n",
    "                                                                  len(lowpass_ratio_audio_samples),\n",
    "                                                                  len(lowpass_ratio_audio_samples)-1,\n",
    "                                                                  nfft, False, True, 'spectrum')\n",
    "\n",
    "    threshold = timbral_util.db2mag(threshold_db)\n",
    "\n",
    "    '''\n",
    "      METRIC 1 - limited weighted mean normalised lower centroid\n",
    "    '''\n",
    "    # define arrays for storing metrics\n",
    "    all_normalised_lower_centroid = []\n",
    "    all_normalised_centroid_tpower = []\n",
    "\n",
    "    # get metrics for e\n",
    "    # ach time segment of the spectrogram\n",
    "    print(\"acm\",spec, time)\n",
    "    for idx in range(len(time)):\n",
    "        # get overall spectrum of time frame\n",
    "        current_spectrum = spec[:, idx]\n",
    "        # calculate time window power\n",
    "        tpower = np.sum(current_spectrum)\n",
    "        all_normalised_centroid_tpower.append(tpower)\n",
    "\n",
    "        # estimate if time segment contains audio energy or just noise\n",
    "        if tpower > threshold:\n",
    "            # get the spectrum\n",
    "            lower_spectrum = lp_centroid_spec[:, idx]\n",
    "            lower_power = np.sum(lower_spectrum)\n",
    "\n",
    "            # get lower centroid\n",
    "            lower_centroid = np.sum(\n",
    "                lower_spectrum * lp_centroid_freq) / float(lower_power)\n",
    "            # append to list\n",
    "            all_normalised_lower_centroid.append(lower_centroid)\n",
    "        else:\n",
    "            all_normalised_lower_centroid.append(0)\n",
    "    # calculate the weighted mean of lower centroids\n",
    "    weighted_mean_normalised_lower_centroid = np.average(all_normalised_lower_centroid,\n",
    "                                                         weights=all_normalised_centroid_tpower)\n",
    "    # limit to the centroid crossover frequency\n",
    "    if weighted_mean_normalised_lower_centroid > centroid_crossover_frequency:\n",
    "        limited_weighted_mean_normalised_lower_centroid = np.float64(\n",
    "            centroid_crossover_frequency)\n",
    "    else:\n",
    "        limited_weighted_mean_normalised_lower_centroid = weighted_mean_normalised_lower_centroid\n",
    "\n",
    "    '''\n",
    "     METRIC 2 - weighted mean normalised lower ratio\n",
    "    '''\n",
    "    # define arrays for storing metrics\n",
    "    all_normalised_lower_ratio = []\n",
    "    all_normalised_ratio_tpower = []\n",
    "\n",
    "    # get metrics for each time segment of the spectrogram\n",
    "    for idx in range(len(time)):\n",
    "        # get time frame of broadband spectrum\n",
    "        current_spectrum = spec[:, idx]\n",
    "        tpower = np.sum(current_spectrum)\n",
    "        all_normalised_ratio_tpower.append(tpower)\n",
    "\n",
    "        # estimate if time segment contains audio energy or just noise\n",
    "        if tpower > threshold:\n",
    "            # get the lowpass spectrum\n",
    "            lower_spectrum = lp_ratio_spec[:, idx]\n",
    "            # get the power of this\n",
    "            lower_power = np.sum(lower_spectrum)\n",
    "            # get the ratio of LF to all energy\n",
    "            lower_ratio = lower_power / float(tpower)\n",
    "            # append to array\n",
    "            all_normalised_lower_ratio.append(lower_ratio)\n",
    "        else:\n",
    "            all_normalised_lower_ratio.append(0)\n",
    "\n",
    "    # calculate\n",
    "    weighted_mean_normalised_lower_ratio = np.average(\n",
    "        all_normalised_lower_ratio, weights=all_normalised_ratio_tpower)\n",
    "\n",
    "    '''\n",
    "      METRIC 3 - Approximate duration/decay-time of sample\n",
    "    '''\n",
    "    all_my_duration = []\n",
    "\n",
    "    # get envelpe of signal\n",
    "    envelope = timbral_util.sample_and_hold_envelope_calculation(\n",
    "        audio_samples, fs)\n",
    "    # estimate onsets\n",
    "    onsets = timbral_util.calculate_onsets(audio_samples, envelope, fs)\n",
    "\n",
    "    # get RMS envelope - better follows decays than the sample-and-hold\n",
    "    rms_step_size = 256\n",
    "    rms_envelope = timbral_util.calculate_rms_enveope(\n",
    "        audio_samples, step_size=rms_step_size)\n",
    "\n",
    "    # convert decay threshold to magnitude\n",
    "    decay_threshold = timbral_util.db2mag(db_decay_threshold)\n",
    "    # rescale onsets to rms stepsize - casting to int\n",
    "    time_convert = fs / float(rms_step_size)\n",
    "    onsets = (np.array(onsets) / float(rms_step_size)).astype('int')\n",
    "\n",
    "    for idx, onset in enumerate(onsets):\n",
    "        if onset == onsets[-1]:\n",
    "            segment = rms_envelope[onset:]\n",
    "        else:\n",
    "            segment = rms_envelope[onset:onsets[idx + 1]]\n",
    "\n",
    "        # get location of max RMS frame\n",
    "        max_idx = np.argmax(segment)\n",
    "        # get the segment from this max until the next onset\n",
    "        post_max_segment = segment[max_idx:]\n",
    "\n",
    "        # estimate duration based on decay or until next onset\n",
    "        if min(post_max_segment) >= decay_threshold:\n",
    "            my_duration = len(post_max_segment) / time_convert\n",
    "        else:\n",
    "            my_duration = np.where(post_max_segment < decay_threshold)[\n",
    "                0][0] / time_convert\n",
    "\n",
    "        # append to array\n",
    "        all_my_duration.append(my_duration)\n",
    "\n",
    "    # calculate the lof of mean duration\n",
    "    mean_my_duration = np.log10(np.mean(all_my_duration))\n",
    "\n",
    "    '''\n",
    "      METRIC 4 - f0 estimation with peak picking\n",
    "    '''\n",
    "    # get the overall spectrum\n",
    "    all_spectrum = np.sum(spec, axis=1)\n",
    "    # normalise this\n",
    "    norm_spec = (all_spectrum - np.min(all_spectrum)) / \\\n",
    "        (np.max(all_spectrum) - np.min(all_spectrum))\n",
    "    # set limit for peak picking\n",
    "    cthr = 0.01\n",
    "    # detect peaks\n",
    "    peak_idx, peak_value, peak_freq = timbral_util.detect_peaks(norm_spec, cthr=cthr, unprocessed_array=norm_spec,\n",
    "                                                                freq=freq)\n",
    "    # estimate peak\n",
    "    pitch_estimate = np.log10(min(peak_freq)) if peak_freq[0] > 0 else 0\n",
    "\n",
    "    # get outputs\n",
    "    if dev_output:\n",
    "        return limited_weighted_mean_normalised_lower_centroid, weighted_mean_normalised_lower_ratio, mean_my_duration, \\\n",
    "            pitch_estimate, weighted_mean_normalised_lower_ratio * mean_my_duration, \\\n",
    "            timbral_util.sigmoid(\n",
    "                weighted_mean_normalised_lower_ratio) * mean_my_duration\n",
    "    else:\n",
    "        '''\n",
    "         Perform linear regression to obtain depth\n",
    "        '''\n",
    "        # coefficients from linear regression\n",
    "        coefficients = np.array([-0.0043703565847874465, 32.83743202462131, 4.750862716905235, -14.217438690256062,\n",
    "                                 3.8782339862813924, -0.8544826091735516, 66.69534393444391])\n",
    "\n",
    "        # what are the best metrics\n",
    "        metric1 = limited_weighted_mean_normalised_lower_centroid\n",
    "        metric2 = weighted_mean_normalised_lower_ratio\n",
    "        metric3 = mean_my_duration\n",
    "        metric4 = pitch_estimate\n",
    "        metric5 = metric2 * metric3\n",
    "        metric6 = timbral_util.sigmoid(metric2) * metric3\n",
    "\n",
    "        # pack metrics into a matrix\n",
    "        all_metrics = np.zeros(7)\n",
    "\n",
    "        all_metrics[0] = metric1\n",
    "        all_metrics[1] = metric2\n",
    "        all_metrics[2] = metric3\n",
    "        all_metrics[3] = metric4\n",
    "        all_metrics[4] = metric5\n",
    "        all_metrics[5] = metric6\n",
    "        all_metrics[6] = 1.0\n",
    "\n",
    "        # perform linear regression\n",
    "        depth = np.sum(all_metrics * coefficients)\n",
    "\n",
    "        if clip_output:\n",
    "            depth = timbral_util.output_clip(depth)\n",
    "\n",
    "        return depth\n",
    "\n",
    "\n",
    "def tf_timbral_depth(audio_tensor, fs, dev_output=False, phase_correction=False, clip_output=False, threshold_db=-60,\n",
    "                     low_frequency_limit=20, centroid_crossover_frequency=2000, ratio_crossover_frequency=500,\n",
    "                     db_decay_threshold=-40):\n",
    "    \"\"\"\n",
    "     This function calculates the apparent Depth of an audio file.\n",
    "     This version of timbral_depth contains self loudness normalising methods and can accept arrays as an input\n",
    "     instead of a string filename.\n",
    "\n",
    "     Version 0.4\n",
    "\n",
    "     Required parameter\n",
    "      :param fname:                        string or numpy array\n",
    "                                           string, audio filename to be analysed, including full file path and extension.\n",
    "                                           numpy array, array of audio samples, requires fs to be set to the sample rate.\n",
    "\n",
    "     Optional parameters\n",
    "      :param fs:                           int/float, when fname is a numpy array, this is a required to be the sample rate.\n",
    "                                           Defaults to 0.\n",
    "      :param phase_correction:             bool, perform phase checking before summing to mono.  Defaults to False.\n",
    "      :param dev_output:                   bool, when False return the depth, when True return all extracted\n",
    "                                           features.  Default to False.\n",
    "      :param threshold_db:                 float/int (negative), threshold, in dB, for calculating centroids.\n",
    "                                           Should be negative.  Defaults to -60.\n",
    "      :param low_frequency_limit:          float/int, low frequency limit at which to highpass filter the audio, in Hz.\n",
    "                                           Defaults to 20.\n",
    "      :param centroid_crossover_frequency: float/int, crossover frequency for calculating the spectral centroid, in Hz.\n",
    "                                           Defaults to 2000\n",
    "      :param ratio_crossover_frequency:    float/int, crossover frequency for calculating the ratio, in Hz.\n",
    "                                           Defaults to 500.\n",
    "\n",
    "      :param db_decay_threshold:           float/int (negative), threshold, in dB, for estimating duration.  Should be\n",
    "                                           negative.  Defaults to -40.\n",
    "\n",
    "      :return:                             float, aparent depth of audio file, float.\n",
    "\n",
    "     Copyright 2018 Andy Pearce, Institute of Sound Recording, University of Surrey, UK.\n",
    "\n",
    "     Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "     you may not use this file except in compliance with the License.\n",
    "     You may obtain a copy of the License at\n",
    "\n",
    "       http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "     Unless required by applicable law or agreed to in writing, software\n",
    "     distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "     See the License for the specific language governing permissions and\n",
    "     limitations under the License.\n",
    "    \"\"\"\n",
    "    '''\n",
    "      Read input\n",
    "    '''\n",
    "    assert len(audio_tensor.get_shape().as_list(\n",
    "    )) == 3, \"tf_timbral_depth :: audio_tensor should be of rank 2 or 3, got {}\".format(audio_tensor)\n",
    "\n",
    "    audio_samples, fs = audio_tensor[:, :, 0], fs\n",
    "    b, n = audio_samples.get_shape().as_list()\n",
    "    # audio_samples is now of format BN\n",
    "    fs = float(fs)\n",
    "    '''\n",
    "      Filter audio\n",
    "    '''\n",
    "    max_val = 1.0 / K.max(K.abs(audio_samples), axis=-1)\n",
    "    # highpass audio - run 3 times to get -18dB per octave - unstable filters produced when using a 6th order\n",
    "    audio_samples = timbral_util.tf_filter_audio_highpass(\n",
    "        audio_samples, crossover=low_frequency_limit, fs=fs)\n",
    "    audio_samples = timbral_util.tf_filter_audio_highpass(\n",
    "        audio_samples, crossover=low_frequency_limit, fs=fs)\n",
    "    audio_samples = timbral_util.tf_filter_audio_highpass(\n",
    "        audio_samples, crossover=low_frequency_limit, fs=fs)\n",
    "\n",
    "    # running 3 times to get -18dB per octave rolloff, greater than second order filters are unstable in python\n",
    "    lowpass_centroid_audio_samples = timbral_util.tf_filter_audio_lowpass(\n",
    "        audio_samples, crossover=centroid_crossover_frequency, fs=fs)\n",
    "    lowpass_centroid_audio_samples = timbral_util.tf_filter_audio_lowpass(\n",
    "        lowpass_centroid_audio_samples, crossover=centroid_crossover_frequency, fs=fs)\n",
    "    lowpass_centroid_audio_samples = timbral_util.tf_filter_audio_lowpass(\n",
    "        lowpass_centroid_audio_samples, crossover=centroid_crossover_frequency, fs=fs)\n",
    "\n",
    "    lowpass_ratio_audio_samples = timbral_util.tf_filter_audio_lowpass(\n",
    "        audio_samples, crossover=ratio_crossover_frequency, fs=fs)\n",
    "    lowpass_ratio_audio_samples = timbral_util.tf_filter_audio_lowpass(\n",
    "        lowpass_ratio_audio_samples, crossover=ratio_crossover_frequency, fs=fs)\n",
    "    lowpass_ratio_audio_samples = timbral_util.tf_filter_audio_lowpass(\n",
    "        lowpass_ratio_audio_samples, crossover=ratio_crossover_frequency, fs=fs)\n",
    "\n",
    "    '''\n",
    "      Get spectrograms and normalise\n",
    "    '''\n",
    "    # normalise audio\n",
    "    max_val = 1.0 / K.max(K.abs(audio_samples), axis=-1)\n",
    "    lowpass_ratio_audio_samples = max_val * lowpass_ratio_audio_samples\n",
    "    lowpass_centroid_audio_samples = max_val*lowpass_centroid_audio_samples\n",
    "    audio_samples = max_val * audio_samples\n",
    "\n",
    "    # set FFT parameters\n",
    "    nfft = 4096\n",
    "    hop_size = int(3*nfft / 4)\n",
    "    # get spectrogram\n",
    "    nn = len(audio_samples[0])\n",
    "    nn_lp = len(lowpass_centroid_audio_samples[0])\n",
    "    nn_lpr = len(lowpass_ratio_audio_samples[0])\n",
    "\n",
    "    if nn > nfft:\n",
    "        freq, time, spec = timbral_util.compat_spectrogram(\n",
    "            audio_samples, fs,\n",
    "            'hamming', nfft, hop_size, nfft,\n",
    "            False, True, 'spectrum')\n",
    "        lp_centroid_freq, _, lp_centroid_spec = timbral_util.compat_spectrogram(lowpass_centroid_audio_samples, fs,\n",
    "                                                                                'hamming', nfft, hop_size, nfft,\n",
    "                                                                                False, True, 'spectrum')\n",
    "        _, _, lp_ratio_spec = timbral_util.compat_spectrogram(lowpass_ratio_audio_samples, fs, 'hamming', nfft,\n",
    "                                                              hop_size, nfft, False, True, 'spectrum')\n",
    "\n",
    "    else:\n",
    "        # file is shorter than 4096, just take the fft\n",
    "        print(\"Hello problem :!\")\n",
    "        freq, time, spec = timbral_util.compat_spectrogram(audio_samples, fs, 'hamming', nn, nn-1,\n",
    "                                                           nfft, False, True, 'spectrum')\n",
    "        lp_centroid_freq, lp_centroid_time, lp_centroid_spec = timbral_util.compat_spectrogram(lowpass_centroid_audio_samples, fs,\n",
    "                                                                                               'hamming',\n",
    "                                                                                               nn_lp,\n",
    "                                                                                               nn_lp-1,\n",
    "                                                                                               nfft, False, True, 'spectrum')\n",
    "        lp_ratio_freq, lp_ratio_time, lp_ratio_spec = timbral_util.compat_spectrogram(lowpass_ratio_audio_samples, fs, 'hamming',\n",
    "                                                                                      nn_lpr,\n",
    "                                                                                      nn_lpr-1,\n",
    "                                                                                      nfft, False, True, 'spectrum')\n",
    "    threshold = timbral_util.db2mag(threshold_db)\n",
    "    # NOTE :: comapt_spectrogram may need to be transposed compared to scipy spectrogram;\n",
    "    '''\n",
    "      METRIC 1 - limited weighted mean normalised lower centroid\n",
    "    '''\n",
    "    all_normalised_centroid_tpower = []\n",
    "    all_normalised_lower_centroid = []\n",
    "    # get metrics for each time segment of the spectrogram\n",
    "\n",
    "    # TODO :: reduce this to this. Should be tested.\n",
    "    all_normalised_lower_centroid_array = []\n",
    "    print(spec, time)\n",
    "    for i in range(b):\n",
    "        for idx in range(len(time)):\n",
    "            # get overall spectrum of time frame\n",
    "            current_spectrum = spec[i, idx, :]\n",
    "            # calculate time window power\n",
    "            tpower = K.sum(current_spectrum)\n",
    "            # estimate if time segment contains audio energy or just noise\n",
    "            if tpower > threshold:\n",
    "                # get the spectrum\n",
    "                lower_spectrum = lp_centroid_spec[i, idx, :]\n",
    "                lower_power = (K.sum(lower_spectrum))\n",
    "                # get lower centroid\n",
    "                lower_centroid = K.sum(\n",
    "                    lower_spectrum * lp_centroid_freq) / float(lower_power)\n",
    "\n",
    "                # append to list\n",
    "                all_normalised_lower_centroid.append(lower_centroid)\n",
    "            else:\n",
    "                all_normalised_lower_centroid.append(float(0))\n",
    "\n",
    "        all_normalised_lower_centroid_array.append(\n",
    "            all_normalised_lower_centroid)\n",
    "    \"\"\"\n",
    "    all_normalised_lower_centroid = K.sum(\n",
    "        lp_centroid_freq * lp_centroid_spec, axis=[2]) / K.sum(K.sqrt(lp_centroid_spec), axis=[1, 2])\n",
    "    all_normalised_lower_centroid = tf.where(tf.math.greater(\n",
    "        all_normalised_centroid_tpower, threshold), all_normalised_lower_centroid, 0.)\n",
    "    \"\"\"\n",
    "    # calculate the weighted mean of lower centroids\n",
    "    \"\"\"\n",
    "    weighted_mean_normalised_lower_centroid = np.average(all_normalised_lower_centroid,\n",
    "                                                         weights=all_normalised_centroid_tpower)\n",
    "    \"\"\"\n",
    "    all_normalised_centroid_tpower = K.sum(spec, axis=-1)\n",
    "    all_normalised_lower_centroid = tf.stack(\n",
    "        all_normalised_lower_centroid_array)\n",
    "    weighted_mean_normalised_lower_centroid = timbral_util.tf_average(\n",
    "        all_normalised_lower_centroid, all_normalised_centroid_tpower, epsilon=None)\n",
    "\n",
    "    # limit to the centroid crossover frequency\n",
    "    \"\"\"\n",
    "    if weighted_mean_normalised_lower_centroid > centroid_crossover_frequency:\n",
    "        limited_weighted_mean_normalised_lower_centroid = np.float64(\n",
    "            centroid_crossover_frequency)\n",
    "    else:\n",
    "        limited_weighted_mean_normalised_lower_centroid = weighted_mean_normalised_lower_centroid\n",
    "    \"\"\"\n",
    "    limited_weighted_mean_normalised_lower_centroid = K.clip(\n",
    "        weighted_mean_normalised_lower_centroid, 0., centroid_crossover_frequency)\n",
    "    # TODO :: convert below.\n",
    "    '''\n",
    "     METRIC 2 - weighted mean normalised lower ratio\n",
    "    '''\n",
    "    # define arrays for storing metrics\n",
    "\n",
    "    all_normalised_lower_ratio_array = []\n",
    "    all_normalised_ratio_tpower_array = []\n",
    "    # get metrics for each time segment of the spectrogram\n",
    "    for i in range(b):\n",
    "        all_normalised_lower_ratio = []\n",
    "        all_normalised_ratio_tpower = []\n",
    "        for idx in range(len(time)):\n",
    "            # get time frame of broadband spectrum\n",
    "            current_spectrum = spec[i, idx, :]\n",
    "            tpower = K.sum(current_spectrum)\n",
    "            all_normalised_ratio_tpower.append(tpower)\n",
    "            # estimate if time segment contains audio energy or just noise\n",
    "            if tpower > threshold:\n",
    "                # get the lowpass spectrum\n",
    "                lower_spectrum = lp_ratio_spec[i, idx, :]\n",
    "                # get the power of this\n",
    "                lower_power = K.sqrt(K.sum(lower_spectrum))\n",
    "\n",
    "                #lower_power = K.sum(lower_spectrum)\n",
    "                # get the ratio of LF to all energy\n",
    "                lower_ratio = lower_power / float(tpower)\n",
    "                # append to array\n",
    "                all_normalised_lower_ratio.append(lower_ratio)\n",
    "            else:\n",
    "                all_normalised_lower_ratio.append(float(0))\n",
    "        all_normalised_lower_ratio_array.append(all_normalised_lower_ratio)\n",
    "        all_normalised_ratio_tpower_array.append(all_normalised_ratio_tpower)\n",
    "    all_normalised_ratio_tpower = tf.stack(all_normalised_ratio_tpower_array)\n",
    "    all_normalised_lower_ratio = tf.stack(all_normalised_lower_ratio_array)\n",
    "    # calculate\n",
    "    weighted_mean_normalised_lower_ratio = timbral_util.tf_average(\n",
    "        all_normalised_lower_ratio, all_normalised_ratio_tpower)\n",
    "\n",
    "    '''\n",
    "      METRIC 3 - Approximate duration/decay-time of sample\n",
    "    '''\n",
    "    all_my_duration = []\n",
    "    \"\"\"\n",
    "    # get envelpe of signal\n",
    "    envelope = timbral_util.tf_sample_and_hold_envelope_calculation(\n",
    "        audio_samples, fs)\n",
    "    # estimate onsets\n",
    "    # onsets = timbral_util.calculate_onsets(audio_samples, envelope, fs)\n",
    "    \"\"\"\n",
    "    onsets = b * [0]\n",
    "    for i in range(b):\n",
    "        # get RMS envelope - better follows decays than the sample-and-hold\n",
    "        rms_step_size = 256\n",
    "        rms_envelope = timbral_util.tf_calculate_rms_enveope(\n",
    "            audio_samples, step_size=rms_step_size)\n",
    "\n",
    "        # convert decay threshold to magnitude\n",
    "        decay_threshold = timbral_util.db2mag(db_decay_threshold)\n",
    "        # rescale onsets to rms stepsize - casting to int\n",
    "        time_convert = fs / float(rms_step_size)\n",
    "        onsets = (np.array(onsets) / float(rms_step_size)).astype('int')\n",
    "\n",
    "        for idx, onset in enumerate(onsets):\n",
    "            if onset == onsets[-1]:\n",
    "                segment = rms_envelope[onset:]\n",
    "            else:\n",
    "                segment = rms_envelope[onset:onsets[idx + 1]]\n",
    "\n",
    "            # get location of max RMS frame\n",
    "            max_idx = np.argmax(segment)\n",
    "            # get the segment from this max until the next onset\n",
    "            post_max_segment = segment[max_idx:]\n",
    "\n",
    "            # estimate duration based on decay or until next onset\n",
    "            if min(post_max_segment) >= decay_threshold:\n",
    "                my_duration = len(post_max_segment) / time_convert\n",
    "            else:\n",
    "                my_duration = np.where(post_max_segment < decay_threshold)[\n",
    "                    0][0] / time_convert\n",
    "\n",
    "            # append to array\n",
    "            all_my_duration.append(my_duration)\n",
    "\n",
    "    # calculate the lof of mean duration\n",
    "    mean_my_duration = timbral_util.tf_log10(\n",
    "        K.mean(tf.stack(all_my_duration), axis=-1))\n",
    "\n",
    "    '''\n",
    "      METRIC 4 - f0 estimation with peak picking\n",
    "    '''\n",
    "    # get the overall spectrum\n",
    "    all_spectrum = K.sum(spec, axis=-1)\n",
    "    # normalise this\n",
    "    norm_spec = (all_spectrum - K.min(all_spectrum, axis=-1)) / \\\n",
    "        (K.max(all_spectrum, axis=-1) - K.min(all_spectrum, axis=-1))\n",
    "    # set limit for peak picking\n",
    "    cthr = 0.01\n",
    "    \"\"\"\n",
    "    peak_idx, _, peak_x = tf.numpy_function(timbral_util.detect_peaks, [\n",
    "                spec, freq, 0.2, spec, fs], [tf.int64, tf.float64, tf.float64])\n",
    "    \"\"\"\n",
    "    # detect peaks\n",
    "    pitch_estimate_array = []\n",
    "    for i in range(b):\n",
    "        _, _, peak_freq = tf.numpy_function(\n",
    "            timbral_util.detect_peaks, [norm_spec[i], freq, cthr, norm_spec[i],  fs], [tf.int64, tf.float64, tf.float64])\n",
    "        # estimate peak\n",
    "        pitch_estimate = timbral_util.tf_log10(\n",
    "            min(peak_freq)) if peak_freq[0] > 0 else float(0)\n",
    "        pitch_estimate_array.append(\n",
    "            tf.cast(pitch_estimate, audio_samples.dtype))\n",
    "    pitch_estimate = tf.stack(pitch_estimate_array)\n",
    "    # get outputs\n",
    "    if dev_output:\n",
    "        return limited_weighted_mean_normalised_lower_centroid, weighted_mean_normalised_lower_ratio, mean_my_duration, \\\n",
    "            pitch_estimate, weighted_mean_normalised_lower_ratio * mean_my_duration, \\\n",
    "            timbral_util.sigmoid(\n",
    "                weighted_mean_normalised_lower_ratio) * mean_my_duration\n",
    "    else:\n",
    "        '''\n",
    "         Perform linear regression to obtain depth\n",
    "        '''\n",
    "        # coefficients from linear regression\n",
    "\n",
    "        # what are the best metrics\n",
    "        metric1 = limited_weighted_mean_normalised_lower_centroid\n",
    "        metric2 = weighted_mean_normalised_lower_ratio\n",
    "        metric3 = mean_my_duration\n",
    "        metric4 = pitch_estimate\n",
    "        metric5 = metric2 * metric3\n",
    "        metric6 = timbral_util.sigmoid(metric2) * metric3\n",
    "        print(\"dev output\", np.array([limited_weighted_mean_normalised_lower_centroid.numpy(), weighted_mean_normalised_lower_ratio.numpy(),\n",
    "                                      mean_my_duration,\n",
    "                                      pitch_estimate.numpy()]).flatten())\n",
    "        # perform linear regression\n",
    "        depth = -0.0043703565847874465 * metric1 + 32.83743202462131*metric2 + 4.750862716905235*metric3 - \\\n",
    "            14.217438690256062*metric4 + 3.8782339862813924*metric5 - \\\n",
    "            0.8544826091735516*metric6 + 66.69534393444391\n",
    "\n",
    "        if clip_output:\n",
    "            depth = timbral_util.output_clip(depth)\n",
    "\n",
    "        return depth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acm [[3.73390787e-10 6.25636566e-08 2.93605012e-08 ... 9.92341327e-12\n",
      "  1.92175163e-12 5.99040553e-12]\n",
      " [1.76335368e-09 1.07719655e-07 7.90347571e-08 ... 3.41499138e-11\n",
      "  7.00273104e-13 1.81446498e-11]\n",
      " [1.12908832e-08 1.31408701e-07 3.18695195e-08 ... 2.20700748e-10\n",
      "  2.55618170e-10 8.71995118e-11]\n",
      " ...\n",
      " [2.28611322e-12 1.29712947e-11 2.61191719e-11 ... 2.29043676e-13\n",
      "  6.66610634e-13 4.60321741e-14]\n",
      " [4.36739563e-12 3.86236461e-12 1.87340637e-12 ... 2.28196421e-12\n",
      "  7.62007875e-13 4.49538246e-13]\n",
      " [7.71420154e-13 1.45832746e-11 2.08029326e-11 ... 4.16539817e-13\n",
      "  1.86585967e-13 9.12412738e-13]] [0.04643991 0.06965986 0.09287982 0.11609977 0.13931973 0.16253968\n",
      " 0.18575964 0.20897959 0.23219955 0.2554195  0.27863946 0.30185941\n",
      " 0.32507937]\n",
      "tf.Tensor(\n",
      "[[[5.2082683e-10 1.8880155e-09 6.9642954e-09 ... 2.2867986e-12\n",
      "   4.3822667e-12 1.5487052e-12]\n",
      "  [1.2686863e-07 1.0589789e-07 1.3023943e-07 ... 1.2934511e-11\n",
      "   3.8441320e-12 2.9120168e-11]\n",
      "  [6.0741598e-08 7.2993700e-08 3.5934242e-08 ... 2.6065409e-11\n",
      "   1.8701555e-12 4.1550652e-11]\n",
      "  ...\n",
      "  [2.0124607e-11 2.9261947e-11 1.1549428e-10 ... 2.2909062e-13\n",
      "   2.2827955e-12 8.3314117e-13]\n",
      "  [4.0290735e-12 9.6016316e-13 1.6548603e-10 ... 6.6722371e-13\n",
      "   7.6225343e-13 3.7359119e-13]\n",
      "  [1.1992561e-11 1.6434552e-11 5.1072351e-11 ... 4.6218488e-14\n",
      "   4.4906749e-13 1.8268002e-12]]], shape=(1, 13, 2049), dtype=float32) tf.Tensor(\n",
      "[6.9659866e-02 1.3931973e-01 2.0897959e-01 ... 1.4259373e+02 1.4266341e+02\n",
      " 1.4273306e+02], shape=(2049,), dtype=float32)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "slice index 13 of dimension 1 out of bounds. [Op:StridedSlice] name: strided_slice/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5d3482628191>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mdy_dx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdy_dx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mtf_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_timbral_depth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_samples_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0macm_score\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtf_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0macm_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"acm score\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macm_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-42813c5cdee5>\u001b[0m in \u001b[0;36mtf_timbral_depth\u001b[0;34m(audio_tensor, fs, dev_output, phase_correction, clip_output, threshold_db, low_frequency_limit, centroid_crossover_frequency, ratio_crossover_frequency, db_decay_threshold)\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m             \u001b[0;31m# get overall spectrum of time frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m             \u001b[0mcurrent_spectrum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m             \u001b[0;31m# calculate time window power\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0mtpower\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_spectrum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m   1011\u001b[0m       \u001b[0mvar_empty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m       \u001b[0mpacked_begin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpacked_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpacked_strides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar_empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m     return strided_slice(\n\u001b[0m\u001b[1;32m   1014\u001b[0m         \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m         \u001b[0mpacked_begin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001b[0m\n\u001b[1;32m   1184\u001b[0m     \u001b[0mstrides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m   op = gen_array_ops.strided_slice(\n\u001b[0m\u001b[1;32m   1187\u001b[0m       \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m       \u001b[0mbegin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[1;32m  10318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10319\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10320\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10321\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10322\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6841\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6842\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6843\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6844\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: slice index 13 of dimension 1 out of bounds. [Op:StridedSlice] name: strided_slice/"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "fname = (\n",
    "    \"/home/ubuntu/Documents/code/data/drummer_1_3_sd_001_hits_snare-drum_sticks_x6.wav\"\n",
    ")\n",
    "fname2 = (\n",
    "    \"/home/ubuntu/Documents/code/data/drummer_3_0_tom_004_hits_low-tom-1_sticks_x5.wav\"\n",
    ")\n",
    "data_dir = \"/home/ubuntu/Documents/code/data/\"\n",
    "\n",
    "tt = 128 * 128\n",
    "\n",
    "fps = glob.glob(os.path.join(data_dir, \"**/*.wav\"), recursive=True)\n",
    "error = []\n",
    "grad = False\n",
    "for fname in fps[:3]:\n",
    "    audio_samples, fs = timbral_util.file_read(\n",
    "        fname, 0, phase_correction=False)\n",
    "    audio_samples_t = tf.convert_to_tensor(\n",
    "        [audio_samples[:tt]], dtype=tf.float32)\n",
    "    audio_samples_t = tf.expand_dims(audio_samples_t, -1)\n",
    "    acm_score = np.array(timbral_depth(fname, dev_output=True))\n",
    "    if grad:\n",
    "        with tf.GradientTape() as g:\n",
    "            g.watch(audio_samples_t)\n",
    "            tf_score = tf_timbral_depth(\n",
    "                audio_samples_t, fs=fs, dev_output=False)\n",
    "        dy_dx = g.gradient(tf_score, audio_samples_t)\n",
    "        assert dy_dx is not None, dy_dx\n",
    "    else:\n",
    "        tf_score = tf_timbral_depth(audio_samples_t, fs=fs, dev_output=False)\n",
    "    error.append(100 * (acm_score - tf_score.numpy()) / acm_score)\n",
    "    print(\"acm score\", acm_score)\n",
    "    print(\"tf score\", tf_score)\n",
    "\n",
    "error = np.array(error)\n",
    "print(\"mean error :: {} %, std :: {}\".format(np.mean(error), np.std(error)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
